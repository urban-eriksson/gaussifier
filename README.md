# gaussifier
Gaussifier / MOAT (Mother Of All Transforms)

The idea behind this transform is inspired by the procedure to remove disparate impact which has been presented previously in the literature which has also been implemented in another repository of mine.

https://github.com/urban-eriksson/ml-datapreprocessing

The idea for this transform, is to take one sample, the training sample, and then assign an aggregated probability density for each of the datapoints. If the datapoints are first sorted this probability is F(x_i) = P(X<=x_i) = (i + 1) / (N + 1) when i goes from 0 to N-1.   

The test data, x_j, j=1..M, can then for instance be linearly interpolated using the point set of x_i and F(x_i), and extrapolated when x_j < min(x_i) or x_j > max(x_i). Quite arbitrarily a gaussian curve form can then be generated by the obtained percent points and the percent point function of the norm module in the stastistical functions of scipy.

https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html

<p align="center"> 
<img src="https://github.com/urban-eriksson/gaussifier/blob/master/images/gaussifier2.png">
</p>
<p align="center"><b>Figure 1.</b> Self transformation of uniform distribution</p>

<p align="center"> 
<img src="https://github.com/urban-eriksson/gaussifier/blob/master/images/gaussifier3.png">
</p>
<p align="center"><b>Figure 1.</b> Self transformation of uniform distribution</p>

